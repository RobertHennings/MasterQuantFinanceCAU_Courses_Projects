---
title: "Tutorial 4"
output:
  pdf_document: default
  html_notebook: default
---

# 1. Inverse transformation method

If the univariate continuous random variable X has a cumulative distribution function $F_X$, then $Y=F_X(X)$ is a standard uniform random variable. Conversely, if Y has a uniform distribution on [0, 1] and if X has an invertible cumulative distribution $F_{X}$, then the random variable $F_{X}^{{-1}}(Y)$ has the same distribution as X. Note that $Q:=F_X^{-1}$ is the quantile function.


Assume X follows an exponential distribution. Draw a sample Y from the standard uniform distribution and use the theorem above to create an exponential distributed sample X based on Y. Visualize your results for different rates ($\lambda\in\{0.01,0.1,1,10\}$) in one graph with four subplots. To this end use 1000 Monte-Carlo-replications.

```{r}

```


# 2. Existence of moments

It was shown in the lecture that the Cauchy distribution (a student-t distribution with one degree of freedom) does not have any moment.

### a)
Draw a large ($n \approx 100000$) sample from a Cauchy distribution. Verify that this sample is indeed Cauchy distributed with the help of a histogram.

```{r}

```

### b) 
Compute the partial means for this sample. The partial mean of a sample $X_1, ... , X_n$ is defined by $\overline{x}_j = \frac{1}{j}\sum_{i=1}^j x_i$.

```{r}

```

### c)
Draw the partial means as a function of n. 

```{r}

```
